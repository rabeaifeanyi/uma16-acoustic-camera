{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabea/micromamba/envs/ba/lib/python3.11/site-packages/acoular/h5files.py:5: UserWarning: We detected that Numpy is already loaded and uses OpenBLAS. Because this conflicts with Numba parallel execution, we disable parallel execution for now and processing might be slower. To speed up, either import Numpy after Acoular or set environment variable OPENBLAS_NUM_THREADS=1 before start of the program.\n",
      "  from .configuration import config\n",
      "2024-08-19 10:57:03.845528: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-19 10:57:03.845555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-19 10:57:03.846306: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-19 10:57:03.851790: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import acoular as ac # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "from config import uma16_index, ConfigUMA\n",
    "import acoupipe.sampler as sp # type: ignore\n",
    "from scipy.stats import uniform # type: ignore\n",
    "import tensorflow as tf # type: ignore\n",
    "from modelsdfg.transformer.config import ConfigBase# type: ignore\n",
    "from scipy.signal import welch # type: ignore\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded signal shape: (44100, 16)\n",
      "Sample freq: 44100.0\n",
      "Number of channels: 16\n"
     ]
    }
   ],
   "source": [
    "folder = \"uma16_example_recordings/\"\n",
    "hdf5_filename = folder + \"450_and_700_1s_h5py.h5\"\n",
    "\n",
    "with h5py.File(hdf5_filename, 'r') as hdf5_file:\n",
    "    signal = hdf5_file['data'][:]\n",
    "    sample_freq = hdf5_file.attrs['sample_freq']\n",
    "    channels = hdf5_file.attrs['channels']\n",
    "\n",
    "print(\"Loaded signal shape:\", signal.shape)\n",
    "print(\"Sample freq:\", sample_freq)\n",
    "print(\"Number of channels:\", channels)\n",
    "\n",
    "fs = sample_freq #Abtastrate\n",
    "t = np.arange(signal.shape[0]) / fs\n",
    "df = 1/fs #Zeitabstand zwischen den Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_csm(signal):\n",
    "    num_of_samples, num_of_channels = signal.shape\n",
    "    fft_signal = np.fft.fft(signal, axis=0)\n",
    "    csm = np.einsum('ij,ik->jk', fft_signal, np.conjugate(fft_signal)) / num_of_samples\n",
    "    \n",
    "    return csm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_csm_welch(signal, fs, nperseg=None, noverlap=None):\n",
    "    freqs, Pxx = welch(signal, fs=fs, nperseg=nperseg, noverlap=noverlap, axis=0)\n",
    "    csm = np.einsum('ij,ik->ijk', Pxx, np.conjugate(Pxx))\n",
    "    return csm, freqs\n",
    "\n",
    "fs = 44100  # Beispielhafte Abtastrate\n",
    "nperseg = 1024  # Anzahl der Samples pro Segment\n",
    "noverlap = 512  # Anzahl der Ã¼berlappenden Samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UMA-16 device: nanoSHARC micArray16 UAC2.0: USB Audio (hw:3,0) at index 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 09:54:36.897049: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:36.958247: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:36.958624: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:36.959823: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:36.960152: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:36.960346: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:37.047129: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:37.047549: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:37.047801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-19 09:54:37.047939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2554 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/home/rabea/Documents/Bachelorarbeit/models/EigmodeTransformer_learning_rate0.00025_epochs500_2024-04-10_19-09\"\n",
    "model_config_path = model_dir + \"/config.toml\"\n",
    "ckpt_path = model_dir + '/ckpt/best_ckpt/0441-0.83.keras'\n",
    "\n",
    "uma_config = ConfigUMA()\n",
    "mic_index = uma16_index()\n",
    "        \n",
    "dev = ac.SoundDeviceSamplesGenerator(device=mic_index, numchannels=16)\n",
    "recording_time = 1\n",
    "dev.numsamples = int(recording_time * dev.sample_freq)\n",
    "t = np.arange(dev.numsamples) / dev.sample_freq\n",
    "        \n",
    "model_config = ConfigBase.from_toml(model_config_path)\n",
    "pipeline = model_config.datasets[1].pipeline.create_instance()\n",
    "ref_mic_index = model_config.datasets[0].pipeline.args['ref_mic_index']\n",
    "model_config.datasets[1].validation.cache=False\n",
    "model = tf.keras.models.load_model(ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(signal):\n",
    "    #csm = calculate_csm(signal)\n",
    "    csm, freqs = calculate_csm_welch(signal, fs, nperseg, noverlap)\n",
    "    eigmode = model.preprocessing(csm[np.newaxis]).numpy()\n",
    "    strength_pred, loc_pred, noise_pred = model.predict(eigmode)\n",
    "    strength_pred = strength_pred.squeeze()\n",
    "    csm_norm = csm[ref_mic_index, ref_mic_index]\n",
    "    csm = csm / csm_norm\n",
    "    strength_pred *= np.real(csm_norm)\n",
    "    loc_pred = pipeline.recover_loc(loc_pred.squeeze(), aperture=uma_config.mics.aperture)\n",
    "    return strength_pred, loc_pred, noise_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'nanoSHARC micArray16 UAC2.0: USB Audio (hw:3,0)', 'index': 5, 'hostapi': 0, 'max_input_channels': 16, 'max_output_channels': 0, 'default_low_input_latency': 0.008684807256235827, 'default_low_output_latency': -1.0, 'default_high_input_latency': 0.034829931972789115, 'default_high_output_latency': -1.0, 'default_samplerate': 44100.0} 44100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 09:54:55.260387: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x5f0dac880840\n",
      "2024-08-19 09:54:55.362719: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: required broadcastable shapes\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'eigmode_preprocessing' (type EigmodePreprocessing).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:Mul] name: \n\nCall arguments received by layer 'eigmode_preprocessing' (type EigmodePreprocessing):\n  â¢ csm=tf.Tensor(shape=(1, 513, 16, 16), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      2\u001b[0m     signal \u001b[38;5;241m=\u001b[39m ac\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mreturn_result(dev, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     strength_pred, loc_pred, noise_pred \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum of sources\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(loc_pred[\u001b[38;5;241m0\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mprediction\u001b[0;34m(signal)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction\u001b[39m(signal):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#csm = calculate_csm(signal)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     csm, freqs \u001b[38;5;241m=\u001b[39m calculate_csm_welch(signal, fs, nperseg, noverlap)\n\u001b[0;32m----> 4\u001b[0m     eigmode \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      5\u001b[0m     strength_pred, loc_pred, noise_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(eigmode)\n\u001b[1;32m      6\u001b[0m     strength_pred \u001b[38;5;241m=\u001b[39m strength_pred\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/micromamba/envs/ba/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/micromamba/envs/ba/lib/python3.11/site-packages/modelsdfg/transformer/layers.py:296\u001b[0m, in \u001b[0;36mEigmodePreprocessing.call\u001b[0;34m(self, csm)\u001b[0m\n\u001b[1;32m    294\u001b[0m neig \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneig\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# get eigmodes\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m eigmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# concatenate real and imaginary part\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat_real_imag:\n",
      "File \u001b[0;32m~/micromamba/envs/ba/lib/python3.11/site-packages/modelsdfg/transformer/layers.py:290\u001b[0m, in \u001b[0;36mEigmodePreprocessing.preprocessing\u001b[0;34m(self, csm, neig)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply the preprocessing to the input tensor.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m:param csm: The input tensor.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m:return: The processed tensor.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m evls, evecs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigh(csm)\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevecs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mneig\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mevls\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mneig\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'eigmode_preprocessing' (type EigmodePreprocessing).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:Mul] name: \n\nCall arguments received by layer 'eigmode_preprocessing' (type EigmodePreprocessing):\n  â¢ csm=tf.Tensor(shape=(1, 513, 16, 16), dtype=float32)"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    signal = ac.tools.return_result(dev, num=256)\n",
    "    strength_pred, loc_pred, noise_pred = prediction(signal)\n",
    "    print(\"num of sources\", len(loc_pred[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
