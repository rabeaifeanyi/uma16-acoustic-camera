{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabea/micromamba/envs/ba/lib/python3.11/site-packages/acoular/h5files.py:5: UserWarning: We detected that Numpy is already loaded and uses OpenBLAS. Because this conflicts with Numba parallel execution, we disable parallel execution for now and processing might be slower. To speed up, either import Numpy after Acoular or set environment variable OPENBLAS_NUM_THREADS=1 before start of the program.\n",
      "  from .configuration import config\n",
      "2024-08-18 14:35:20.935191: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:35:20.935217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:35:20.936044: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:35:20.942277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import acoular as ac # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "from uma16_acoustic_camera.config import uma16_index, ConfigUMA\n",
    "import acoupipe.sampler as sp # type: ignore\n",
    "from scipy.stats import uniform # type: ignore\n",
    "import tensorflow as tf # type: ignore\n",
    "from modelsdfg.transformer.config import ConfigBase# type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_csm(signal):\n",
    "    num_of_samples, num_of_channels = signal.shape\n",
    "    fft_signal = np.fft.fft(signal, axis=0)\n",
    "    csm = np.einsum('ij,ik->jk', fft_signal, np.conjugate(fft_signal)) / num_of_samples\n",
    "    \n",
    "    return csm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UMA-16 device: nanoSHARC micArray16 UAC2.0: USB Audio (hw:3,0) at index 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/home/rabea/Documents/Bachelorarbeit/models/EigmodeTransformer_learning_rate0.00025_epochs500_2024-04-10_19-09\"\n",
    "model_config_path = model_dir + \"/config.toml\"\n",
    "ckpt_path = model_dir + '/ckpt/best_ckpt/0441-0.83.keras'\n",
    "\n",
    "uma_config = ConfigUMA()\n",
    "mic_index = uma16_index()\n",
    "        \n",
    "dev = ac.SoundDeviceSamplesGenerator(device=mic_index, numchannels=16)\n",
    "recording_time = 1\n",
    "dev.numsamples = int(recording_time * dev.sample_freq)\n",
    "t = np.arange(dev.numsamples) / dev.sample_freq\n",
    "        \n",
    "model_config = ConfigBase.from_toml(model_config_path)\n",
    "pipeline = model_config.datasets[1].pipeline.create_instance()\n",
    "ref_mic_index = model_config.datasets[0].pipeline.args['ref_mic_index']\n",
    "model_config.datasets[1].validation.cache=False\n",
    "model = tf.keras.models.load_model(ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(signal):\n",
    "    csm = calculate_csm(signal)\n",
    "    eigmode = model.preprocessing(csm[np.newaxis]).numpy()\n",
    "    strength_pred, loc_pred, noise_pred = model.predict(eigmode)\n",
    "    strength_pred = strength_pred.squeeze()\n",
    "    csm_norm = csm[ref_mic_index, ref_mic_index]\n",
    "    csm = csm / csm_norm\n",
    "    strength_pred *= np.real(csm_norm)\n",
    "    loc_pred = pipeline.recover_loc(loc_pred.squeeze(), aperture=uma_config.mics.aperture)\n",
    "    return strength_pred, loc_pred, noise_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'nanoSHARC micArray16 UAC2.0: USB Audio (hw:3,0)', 'index': 5, 'hostapi': 0, 'max_input_channels': 16, 'max_output_channels': 0, 'default_low_input_latency': 0.008684807256235827, 'default_low_output_latency': -1.0, 'default_high_input_latency': 0.034829931972789115, 'default_high_output_latency': -1.0, 'default_samplerate': 44100.0} 44100.0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "num of sources 8\n",
      "{'name': 'nanoSHARC micArray16 UAC2.0: USB Audio (hw:3,0)', 'index': 5, 'hostapi': 0, 'max_input_channels': 16, 'max_output_channels': 0, 'default_low_input_latency': 0.008684807256235827, 'default_low_output_latency': -1.0, 'default_high_input_latency': 0.034829931972789115, 'default_high_output_latency': -1.0, 'default_samplerate': 44100.0} 44100.0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "num of sources 8\n",
      "{'name': 'nanoSHARC micArray16 UAC2.0: USB Audio (hw:3,0)', 'index': 5, 'hostapi': 0, 'max_input_channels': 16, 'max_output_channels': 0, 'default_low_input_latency': 0.008684807256235827, 'default_low_output_latency': -1.0, 'default_high_input_latency': 0.034829931972789115, 'default_high_output_latency': -1.0, 'default_samplerate': 44100.0} 44100.0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "num of sources 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    signal = ac.tools.return_result(dev, num=256)\n",
    "    strength_pred, loc_pred, noise_pred = prediction(signal)\n",
    "    print(\"num of sources\", len(loc_pred[0]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
